{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL\n",
    "\n",
    "## Learning to Optimize Rewards\n",
    "\n",
    "In RL, a software agent makes observations and takes actions within an environment, and in return it receives rewards.  \n",
    "\n",
    "## Policy Search\n",
    "\n",
    "The algorithm a software agent uses to determine its actions is called its __policy__.  \n",
    "The policy could be a NN taking observations as inputs and outputting the action to take.  \n",
    "\n",
    "If policy involves randomness, it is called a _stochastic policy_.  \n",
    "\n",
    "1) Genetic algorithms  \n",
    "2) Policy gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02910841  0.01107512 -0.02014337 -0.01282661]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "obs = env.reset()\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`obs = [x, x_velocity, angle, angular_velocity]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_policy(obs):\n",
    "    angle = obs[2]\n",
    "    return 0 if angle < 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_basic_policy():\n",
    "    totals = []\n",
    "    for ep in range(500):\n",
    "        ep_rewards = 0\n",
    "        obs = env.reset()\n",
    "        for step in range(200):\n",
    "            env.render()\n",
    "            action = basic_policy(obs)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            ep_rewards += reward\n",
    "            if done:\n",
    "                break\n",
    "        totals.append(ep_rewards)\n",
    "    return totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = run_basic_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'totals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-212d0f95531b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'totals' is not defined"
     ]
    }
   ],
   "source": [
    "np.mean(totals), np.std(totals), np.min(totals), np.max(totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 4\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(5, activation='elu', input_shape=[n_inputs,]),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit assignment problem, discount factor $\\gamma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_step(env, obs, model, loss_fn):\n",
    "    with tf.GradientTape() as tape:\n",
    "        left_proba = model(obs[np.newaxis])\n",
    "        action = (tf.random.uniform([1,1]) > left_proba)\n",
    "        y_target = tf.constant([[1.]]) - tf.cast(action, tf.float32)\n",
    "        loss = tf.reduce_mean(loss_fn(y_target, left_proba))\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    obs, reward, done, info = env.step(int(action[0,0].numpy()))\n",
    "    return obs, reward, done, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_multiple_episodes(env, n_episodes, n_max_steps, model, loss_fn):\n",
    "    all_rewards = []\n",
    "    all_grads = []\n",
    "    for episode in range(n_episodes):\n",
    "        current_rewards = []\n",
    "        current_grads = []\n",
    "        obs = env.reset()\n",
    "        for step in range(n_max_steps):\n",
    "            obs, reward, done, grads = play_one_step(env, obs, model, loss_fn)\n",
    "            current_rewards.append(reward)\n",
    "            current_grads.append(grads)\n",
    "            if done:\n",
    "                break\n",
    "        all_rewards.append(current_rewards)\n",
    "        all_grads.append(current_grads)\n",
    "    return all_rewards, all_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, discount_factor):\n",
    "    discounted = np.array(rewards)\n",
    "    for step in range(len(rewards) - 2, -1, -1):\n",
    "        discounted[step] += discounted[step + 1] * discount_factor\n",
    "    return discounted\n",
    "\n",
    "def discount_and_normalize_rewards(all_rewards, discount_factor):\n",
    "    all_discounted_rewards = [discount_rewards(rewards, discount_factor) for rewards in all_rewards]\n",
    "    flat_rewards = np.concatenate(all_discounted_rewards)\n",
    "    reward_mean = flat_rewards.mean()\n",
    "    reward_std = flat_rewards.std()\n",
    "    return [(discounted_rewards - reward_mean) / reward_std for discounted_rewards in all_discounted_rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-22, -40, -50])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discount_rewards([10, 0, -50], discount_factor=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.28435071, -0.86597718, -1.18910299]),\n",
       " array([1.26665318, 1.0727777 ])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discount_and_normalize_rewards([[10, 0, -50], [10, 20]], discount_factor=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 150\n",
    "n_episodes_per_update = 10\n",
    "n_max_steps = 200\n",
    "discount_factor = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "loss_fn = keras.losses.binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for iter in range(n_iterations):\n",
    "        all_rewards, all_grads = play_multiple_episodes(env, n_episodes_per_update, n_max_steps, model, loss_fn)\n",
    "        all_final_rewards = discount_and_normalize_rewards(all_rewards, discount_factor)\n",
    "        \n",
    "        all_mean_grads = []\n",
    "        for vi in range(len(model.trainable_variables)):\n",
    "            mean_grads = tf.reduce_mean([final_reward * all_grads[episode_index][step][vi] \n",
    "             for episode_index, final_rewards in enumerate(all_final_rewards) \n",
    "                 for step, final_reward in enumerate(final_rewards)], axis=0)\n",
    "            all_mean_grads.append(mean_grads)\n",
    "        optimizer.apply_gradients(zip(all_mean_grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def test():\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        time.sleep(0.05)\n",
    "        env.render()\n",
    "        action = model(obs[np.newaxis])\n",
    "        obs, reward, done, _ = env.step(int(action[0,0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Decision Process\n",
    "\n",
    "## Bellman Optimality Equation\n",
    "\n",
    "Bellman fount a way to estimate the _optimal state_ value of any state $s$, noted $V^*(s)$, which is the sum of all discounted future rewards the agent can expect on average after it reaches a state s, assuming it acts optimally.  \n",
    "This recursive equation says that if the agent acts optimally, then the optimal value of the current state is equal to the reward it will get on average after taking one optimal action, plus the expected optimal value of all possible next states that this action can lead to.  \n",
    "\n",
    "\n",
    "$V^*(s) = max_a \\sum_s T(s,a,s') \\left[R(s, a, s') + \\gamma V^*(s') \\right] \\text{  for all s}$\n",
    "\n",
    "### Value Iteration algorithm\n",
    "\n",
    "$V_{k+1}(s) \\leftarrow max_a \\sum_{s'} T(s,a,s') \\left[ R(s,a,s') + \\gamma V_k(s') \\right] \\text {   for all s}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-values (Quality Values)\n",
    "State-action values (Q-Values).  The optimal Q-Value of the state-action pair (s,a) noted $Q^*(s,a)$, is the sum of discounted future rewards tha gent can expect on average after it reaches the state s and chooses action a, but before it sees the outcome of this action, assuming it acts optimally after that action.  \n",
    "\n",
    "Start with initialization all the Q-Value estimates to zero, then you update them using the Q-Value Iteration algorthm  \n",
    "$Q_{k+1}(s,a) \\leftarrow \\sum_{s'}T(s,a,s')\\left[ R(s,a,s') + \\gamma max_{a'} Q_k(s',a') \\right]$   \n",
    "\n",
    "Thus Optimal Policy $\\pi^*(s) = argmax_a Q^*(s,a)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.90 # the discount factor\n",
    "\n",
    "transition_probabilities = [ # shape=[s, a, s']\n",
    "    [[0.7, 0.3, 0.0], [1.0, 0.0, 0.0], [0.8, 0.2, 0.0]],\n",
    "    [[0.0, 1.0, 0.0], None, [0.0, 0.0, 1.0]],\n",
    "    [None, [0.8, 0.1, 0.1], None]]\n",
    "rewards = [ # shape=[s, a, s']\n",
    "    [[+10, 0, 0], [0, 0, 0], [0, 0, 0]],\n",
    "    [[0, 0, 0], [0, 0, 0], [0, 0, -50]],\n",
    "    [[0, 0, 0], [+40, 0, 0], [0, 0, 0]]]\n",
    "possible_actions = [[0, 1, 2], [0, 2], [1]]\n",
    "\n",
    "Q_values = np.full((3, 3), -np.inf) # -np.inf for impossible actions\n",
    "for state, actions in enumerate(possible_actions):\n",
    "    Q_values[state, actions] = 0.0 # for all possible actions\n",
    "\n",
    "for iteration in range(50):\n",
    "    Q_prev = Q_values.copy()\n",
    "    for s in range(3):\n",
    "        for a in possible_actions[s]:\n",
    "            Q_values[s, a] = np.sum([transition_probabilities[s][a][sp] * (rewards[s][a][sp] + gamma * np.max(Q_prev[sp]))\n",
    "                for sp in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Q_values, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Difference Learning\n",
    "\n",
    "RL problems with discrete actions can often be modeled as Markov decision processes, but the agnet initially has no idea what the transition probabilities are, and it does not know what the rewards are going to be iether. it must experience each state and each transition at least once to know the rewards, and it must experience them multiple times if it is to have a reasonable estimate of the transition probabilities.  \n",
    "\n",
    "The _Temporal Difference Learning_ (TD Learning) algorithm is very similar to the Value Iteration algorithm, but tweaked to make into account the fact that the agent has only partial knowledge of the MDP. In general we assume that  the agent initially knows only the possible states and actions, and nothing more. The agent uses and _exploration policy_ - for example, a purely random policy - to explore the MDP, and as it progresses, the TD Learning algorithm updates the estimates of the state values based on the transitions and rewards athat are actually observed.  \n",
    "\n",
    "$V_{k+1}(s) \\leftarrow V_k(s) + \\alpha \\delta_k(s,r,s')$  \n",
    "$\\delta_k(s,r,s') = r + \\gamma V_k(s') - V_k(s)$\n",
    "\n",
    "- $\\alpha$ - learning rate (0.01)  \n",
    "- $r + \\gamma V_k(s')$ is called the TD _target_  \n",
    "- $\\delta_k(s,r,s')$ is called the TD _error_  \n",
    "\n",
    "\n",
    "For each state s, this algorithm simply keeps track of a running average of the immediate rewards the agnet gets upon leaving that state, plus the rewards it expects to get later (assuming it acts optimally).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning\n",
    "\n",
    "Adaptation of the Q-Value Iteration algorithm, where the transition probabilities and the rewards are initially unknown.  \n",
    "$Q(s,a) \\leftarrow_\\alpha r + \\gamma \\max_{a'}Q(s',a')$  \n",
    "\n",
    "For each state-action pair (s,a), this algorithm keeps track of a runnning average of the rewards r the agent gets upon leaving the state s with action a, plut the sum of discounted future rewards it expects to get. To estimate this sum, we take the maximum of the Q-Value estimates for the next state s', since we assume that the target policy would act optimally from then on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(state, action):\n",
    "    probas = transition_probabilities[state][action]\n",
    "    next_state = np.random.choice([0,1,2], p=probas)\n",
    "    reward = rewards[state][action][next_state]\n",
    "    return next_state, reward\n",
    "\n",
    "def exploration_policy(state):\n",
    "    return np.random.choice(possible_actions[state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha0 = 0.05\n",
    "decay = 0.005\n",
    "gamma = 0.9\n",
    "state = 0\n",
    "\n",
    "for iteration in range(10000):\n",
    "    action = exploration_policy(state)\n",
    "    next_state, reward = step(state, action)\n",
    "    next_value = np.max(Q_values[next_state])\n",
    "    alpha = alpha0 / (1+iteration * decay)\n",
    "    Q_values[state, action] *= 1 - alpha\n",
    "    Q_values[state, action] += alpha * (reward + gamma * next_value)\n",
    "    state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Off-policy vs On-policy algorithm\n",
    "\n",
    "An algorithm is called _off-policy_ if the policy being trained is not necessarily the one being executed.  \n",
    "Policy Gradients algorithm is _on-policy_ algorithm: it explores the world using the policy being trained.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration Policies\n",
    "\n",
    "$\\epsilon$_-greedy policy_ (act randomly with probability $\\epsilon$, or 1-$\\epsilon$ take the highest Q-Value)  \n",
    "\n",
    "$Q(s,a) \\leftarrow_\\alpha r + \\gamma max_{a'} f(Q(s',a'), N(s',a'))$  \n",
    "- $N(s',a')$ counts the number of times the action a' was chisen in state s'\n",
    "- $f(Q,N)$ is an exploration function, such as $f(Q,N) = Q + k/(1+N)$, k is a curiosity hyperparameter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "input_shape = [4]\n",
    "\n",
    "n_outputs = 2\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(32, activation='elu', input_shape=input_shape),\n",
    "    keras.layers.Dense(32, activation='elu'),\n",
    "    keras.layers.Dense(n_outputs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(state, epsilon=0):\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.randint(2)\n",
    "    else:\n",
    "        Q_values = model.predict(state[np.newaxis])\n",
    "        return np.argmax(Q_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "\n",
    "replay_buffer = deque(maxlen=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_experiences(batch_size):\n",
    "    items = random.sample(replay_buffer, batch_size)\n",
    "    s, a, r, ns, d = zip(*items)\n",
    "    return map(np.array, [s, a, r, ns, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_step(env, state, epsilon):\n",
    "    action = epsilon_greedy_policy(state, epsilon)\n",
    "    ns, r, d, i = env.step(action)\n",
    "    replay_buffer.append((state, action, r, ns, d))\n",
    "    return ns, r, d, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "discount_factor = 0.95\n",
    "optimizer = keras.optimizers.Adam(lr=1e-3)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "def training_step(batch_size):\n",
    "    states, actions, rewards, new_states, dones = sample_experiences(batch_size)\n",
    "    next_Q_values = model.predict(new_states)\n",
    "    max_next_Q_values = np.max(next_Q_values, axis=1)\n",
    "    target_Q_values = (rewards + (1-dones) * discount_factor * max_next_Q_values)\n",
    "    mask = tf.one_hot(actions, n_outputs)\n",
    "    with tf.GradientTape() as tape:\n",
    "        all_Q_values = model(states)\n",
    "        Q_values = tf.reduce_sum(all_Q_values * mask, axis=1, keepdims=True)\n",
    "        loss = tf.reduce_mean(loss_fn(target_Q_values, Q_values))\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "\n",
    "for episode in range(600):\n",
    "    obs = env.reset()\n",
    "    for step in range(200):\n",
    "        epsilon = max(1. - episode / 500., 0.01)\n",
    "        obs, r, d, i = play_one_step(env, obs, epsilon)\n",
    "        if d:\n",
    "            rewards.append(step)\n",
    "            break\n",
    "    if episode > 50:\n",
    "        training_step(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = np.array(rewards)\n",
    "rewards = pd.Series(rewards)\n",
    "means = rewards.rolling(50).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(0, len(rewards)), rewards)\n",
    "plt.plot(range(len(rewards) - len(means), len(rewards)), means)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sudden drops on a plot is called `Catastrophic forgetting`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Learning variants\n",
    "\n",
    "## Fixed Q-Value networks\n",
    "\n",
    "Tandem of `online` and `target` networks: `target` network makes predictions and `online` is learning. Each `k` episodes weights of target network are updated.  \n",
    "\n",
    "## Double DQN\n",
    "\n",
    "DeepMind researchers tweaked their DQN algorithm,\n",
    "increasing its performance and somewhat stabilizing training. They called this\n",
    "variant Double DQN. The update was based on the observation that the target\n",
    "network is prone to overestimating Q-Values. Indeed, suppose all actions are\n",
    "equally good: the Q-Values estimated by the target model should be identical,\n",
    "but since they are approximations, some may be slightly greater than others, by\n",
    "pure chance. The target model will always select the largest Q-Value, which will\n",
    "be slightly greater than the mean Q-Value, most likely overestimating the true QValue\n",
    "(a bit like counting the height of the tallest random wave when measuring\n",
    "the depth of a pool). To fix this, they proposed using the online model instead of\n",
    "the target model when selecting the best actions for the next states, and using the\n",
    "target model only to estimate the Q-Values for these best actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(batch_size):\n",
    "    experiences = sample_experiences(batch_size)\n",
    "    states, actions, rewards, next_states, dones = experiences\n",
    "    next_Q_values = model.predict(next_states)\n",
    "    best_next_actions = np.argmax(next_Q_values, axis=1)\n",
    "    next_mask = tf.one_hot(best_next_actions, n_outputs).numpy()\n",
    "    next_best_Q_values = (target.predict(next_states) * next_mask).sum(axis=1)\n",
    "    target_Q_values = (rewards + (1 - dones) * discount_factor * next_best_Q_values)\n",
    "    mask = tf.one_hot(actions, n_outputs)\n",
    "    [...] # the rest is the same as earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prioritized Experience Replay\n",
    "\n",
    "Instead of sampling experiences uniformly from the replay buffer, why not\n",
    "sample important experiences more frequently? This idea is called importance\n",
    "sampling (IS) or prioritized experience replay (PER), and it was introduced in a\n",
    "2015 paper by DeepMind researchers (once again!).  \n",
    "\n",
    "More specifically, experiences are considered important if they are likely to\n",
    "lead to fast learning progress. But how can we estimate this? One reasonable\n",
    "approach is to measure the magnitude of the TD error  = r + V(s)  V(s). A\n",
    "large TD error indicates that a transition (s, r, s) is very surprising, and thus\n",
    "probably worth learning from. When an experience is recorded in the replay\n",
    "buffer, its priority is set to a very large value, to ensure that it gets sampled at\n",
    "least once. However, once it is sampled (and every time it is sampled), the TD\n",
    "error  is computed, and this experiences priority is set to p = || (plus a small\n",
    "constant to ensure that every experience has a non-zero probability of being\n",
    "sampled). The probability P of sampling an experience with priority p is\n",
    "proportional to p , where  is a hyperparameter that controls how greedy we\n",
    "want importance sampling to be: when  = 0, we just get uniform sampling, and\n",
    "when  = 1, we get full-blown importance sampling. In the paper, the authors\n",
    "used  = 0.6, but the optimal value will depend on the task.  \n",
    "\n",
    "## Dueling DQN\n",
    "\n",
    "The Dueling DQN algorithm (DDQN, not to be confused with Double DQN,\n",
    "although both techniques can easily be combined) was introduced in yet another\n",
    "2015 paper by DeepMind researchers. To understand how it works, we must\n",
    "first note that the Q-Value of a state-action pair (s, a) can be expressed as Q(s, a)\n",
    "= V(s) + A(s, a), where V(s) is the value of state s and A(s, a) is the advantage of\n",
    "taking the action a in state s, compared to all other possible actions in that state.\n",
    "Moreover, the value of a state is equal to the Q-Value of the best action a for\n",
    "that state (since we assume the optimal policy will pick the best action), so V(s)\n",
    "= Q(s, a ), which implies that A(s, a ) = 0. In a Dueling DQN, the model\n",
    "estimates both the value of the state and the advantage of each possible action.\n",
    "Since the best action should have an advantage of 0, the model subtracts the\n",
    "maximum predicted advantage from all predicted advantages.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
